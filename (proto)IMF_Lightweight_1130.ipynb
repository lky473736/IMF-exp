{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gs-G42KhUQre",
        "outputId": "f5e11e12-c6e4-4f39-d393-e7e36b7aaa12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: NVIDIA A100-SXM4-40GB\n",
            "GPU Memory: 39.56 GB\n",
            "======================================================================\n",
            "CONFIGURATION\n",
            "======================================================================\n",
            "Batch Size: 512 (Effective: 1024)\n",
            "Gradient Accumulation Steps: 2\n",
            "Epochs: 50\n",
            "Learning Rate: 0.001\n",
            "Hidden Dim: 128 | Latent Dim: 64\n",
            "SIREN Layers: 3 | Frequencies: 16\n",
            "Mixed Precision: True\n",
            "Num Workers: 4\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "LOADING DATASETS\n",
            "======================================================================\n",
            "\n",
            "[UCI-HAR] Loading from: /content/drive/MyDrive/HAR_Dataset/UCI\n",
            "  Loading: total_acc_x_train.txt\n",
            "  Loading: total_acc_y_train.txt\n",
            "  Loading: total_acc_z_train.txt\n",
            "  Loading: body_acc_x_train.txt\n",
            "  Loading: body_acc_y_train.txt\n",
            "  Loading: body_acc_z_train.txt\n",
            "  Loading: body_gyro_x_train.txt\n",
            "  Loading: body_gyro_y_train.txt\n",
            "  Loading: body_gyro_z_train.txt\n",
            "  Loading: total_acc_x_test.txt\n",
            "  Loading: total_acc_y_test.txt\n",
            "  Loading: total_acc_z_test.txt\n",
            "  Loading: body_acc_x_test.txt\n",
            "  Loading: body_acc_y_test.txt\n",
            "  Loading: body_acc_z_test.txt\n",
            "  Loading: body_gyro_x_test.txt\n",
            "  Loading: body_gyro_y_test.txt\n",
            "  Loading: body_gyro_z_test.txt\n",
            "  Train: (7352, 128, 9), Test: (2947, 128, 9)\n",
            "\n",
            "[WISDM] Loading from: /content/drive/MyDrive/HAR_Dataset/WISDM\n",
            "  Found: WISDM_ar_v1.1_raw.txt\n",
            "  Processing: WISDM_ar_v1.1_raw.txt\n",
            "  Train: (19030, 3, 80), Test: (8156, 3, 80)\n",
            "\n",
            "[PAMAP2] Loading from: /content/drive/MyDrive/HAR_Dataset/PAMAP2\n",
            "  Found 14 subject files\n",
            "  Processing: subject101.dat\n",
            "  Processing: subject102.dat\n",
            "  Processing: subject103.dat\n",
            "  Processing: subject104.dat\n",
            "  Processing: subject105.dat\n",
            "  Processing: subject106.dat\n",
            "  Processing: subject107.dat\n",
            "  Processing: subject108.dat\n",
            "  Processing: subject109.dat\n",
            "  Processing: subject101.dat\n",
            "  Processing: subject105.dat\n",
            "  Processing: subject106.dat\n",
            "  Processing: subject108.dat\n",
            "  Processing: subject109.dat\n",
            "  Train: (27190, 18, 100), Test: (11653, 18, 100)\n",
            "\n",
            "[MHEALTH] Loading from: /content/drive/MyDrive/HAR_Dataset/MHEALTH\n",
            "  Found 10 subject files\n",
            "  Processing: mHealth_subject1.log\n",
            "  Processing: mHealth_subject10.log\n",
            "  Processing: mHealth_subject2.log\n",
            "  Processing: mHealth_subject3.log\n",
            "  Processing: mHealth_subject4.log\n",
            "  Processing: mHealth_subject5.log\n",
            "  Processing: mHealth_subject6.log\n",
            "  Processing: mHealth_subject7.log\n",
            "  Processing: mHealth_subject8.log\n",
            "  Processing: mHealth_subject9.log\n",
            "  Train: (9599, 21, 50), Test: (4115, 21, 50)\n",
            "\n",
            "[MobiAct] Loading from: /content/drive/MyDrive/HAR_Dataset/MOBIACT\n",
            "  Found 9 subjects\n",
            "  Processing subject: sub10\n",
            "  Processing subject: sub11\n",
            "  Processing subject: sub2\n",
            "  Processing subject: sub3\n",
            "  Processing subject: sub4\n",
            "  Processing subject: sub5\n",
            "  Processing subject: sub7\n",
            "  Processing subject: sub8\n",
            "  Processing subject: sub9\n",
            "  Train: (10882, 9, 100), Test: (4665, 9, 100)\n",
            "\n",
            "[MotionSense] Loading from: /content/drive/MyDrive/HAR_Dataset/MOTIONSENSE\n",
            "  Found 351 CSV files\n",
            "  Processing training files...\n",
            "  Processing validation files...\n",
            "  Train: (16010, 12, 128), Test: (4510, 12, 128)\n",
            "\n",
            "Loaded 6 datasets: ['UCI-HAR', 'WISDM', 'PAMAP2', 'MHEALTH', 'MobiAct', 'MotionSense']\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: UCI-HAR\n",
            "======================================================================\n",
            "Train samples: 7352\n",
            "Test samples: 2947\n",
            "Input shape: (128, 9)\n",
            "Classes: 6\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 282,742 (0.28M)\n",
            "Trainable Parameters: 282,726 (0.28M)\n",
            "FLOPs: 1.99M\n",
            "Params (thop): 0.28M\n",
            "Inference Time: 1.48ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: UCI-HAR\n",
            "======================================================================\n",
            "TRAIN - Loss: 1.9963 | Acc: 45.50%\n",
            "   CE: 1.4799 | Recon: 0.9982 | Vel: 0.0000 | Smooth: 1.7304\n",
            "TEST  - Loss: 1.6180 | Acc: 50.08% | F1: 40.16% | Prec: 48.59% | Rec: 50.08%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.22 GB\n",
            "New best model saved! Acc: 50.08% | F1: 40.16%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: UCI-HAR\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.5644 | Acc: 96.11%\n",
            "   CE: 0.0811 | Recon: 0.9377 | Vel: 0.0000 | Smooth: 1.4513\n",
            "TEST  - Loss: 0.9243 | Acc: 87.44% | F1: 87.41% | Prec: 87.65% | Rec: 87.44%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.23 GB\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: UCI-HAR\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.5009 | Acc: 98.08%\n",
            "   CE: 0.0400 | Recon: 0.8885 | Vel: 0.0000 | Smooth: 1.6589\n",
            "TEST  - Loss: 1.0603 | Acc: 84.70% | F1: 84.65% | Prec: 84.71% | Rec: 84.70%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.23 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - UCI-HAR\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[438  20  23   2  12   1]\n",
            " [ 51 391  28   0   1   0]\n",
            " [  5  27 388   0   0   0]\n",
            " [  2   3   0 381 100   5]\n",
            " [  9   0   0  64 459   0]\n",
            " [  0   1   4   1   0 531]]\n",
            "Confusion matrix saved: confusion_matrix_UCI-HAR.png\n",
            "t-SNE plot saved: tsne_UCI-HAR.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  Walking: 88.31%\n",
            "  Walking Upstairs: 83.01%\n",
            "  Walking Downstairs: 92.38%\n",
            "  Sitting: 77.60%\n",
            "  Standing: 86.28%\n",
            "  Laying: 98.88%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - UCI-HAR\n",
            "======================================================================\n",
            "Accuracy:  87.82%\n",
            "F1 Score:  87.78%\n",
            "Precision: 87.89%\n",
            "Recall:    87.82%\n",
            "Params:    0.28M\n",
            "FLOPs:     1.99M\n",
            "Inference: 1.48ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: WISDM\n",
            "======================================================================\n",
            "Train samples: 19030\n",
            "Test samples: 8156\n",
            "Input shape: (3, 80)\n",
            "Classes: 6\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 102,617 (0.10M)\n",
            "Trainable Parameters: 102,601 (0.10M)\n",
            "FLOPs: 9.25M\n",
            "Params (thop): 0.10M\n",
            "Inference Time: 1.55ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: WISDM\n",
            "======================================================================\n",
            "TRAIN - Loss: 1.6642 | Acc: 58.94%\n",
            "   CE: 1.1311 | Recon: 1.0070 | Vel: 0.0000 | Smooth: 2.9546\n",
            "TEST  - Loss: 1.2226 | Acc: 73.80% | F1: 64.32% | Prec: 58.28% | Rec: 73.80%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.23 GB\n",
            "New best model saved! Acc: 73.80% | F1: 64.32%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: WISDM\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.4902 | Acc: 99.00%\n",
            "   CE: 0.0338 | Recon: 0.8875 | Vel: 0.0000 | Smooth: 1.2649\n",
            "TEST  - Loss: 0.5535 | Acc: 97.01% | F1: 96.98% | Prec: 97.11% | Rec: 97.01%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.27 GB\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: WISDM\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.3786 | Acc: 99.86%\n",
            "   CE: 0.0063 | Recon: 0.7387 | Vel: 0.0000 | Smooth: 0.2923\n",
            "TEST  - Loss: 0.4182 | Acc: 98.97% | F1: 98.97% | Prec: 98.97% | Rec: 98.97%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.27 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - WISDM\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 710    2    0    0   23    4]\n",
            " [   0 2541    0    0    8    3]\n",
            " [   0    0  435    3    1    0]\n",
            " [   0    0    2  350    0    0]\n",
            " [   8    8    0    2  888    1]\n",
            " [   8    1    0    0    3 3155]]\n",
            "Confusion matrix saved: confusion_matrix_WISDM.png\n",
            "t-SNE plot saved: tsne_WISDM.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  Downstairs: 96.08%\n",
            "  Jogging: 99.57%\n",
            "  Sitting: 99.09%\n",
            "  Standing: 99.43%\n",
            "  Upstairs: 97.91%\n",
            "  Walking: 99.62%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - WISDM\n",
            "======================================================================\n",
            "Accuracy:  99.06%\n",
            "F1 Score:  99.06%\n",
            "Precision: 99.06%\n",
            "Recall:    99.06%\n",
            "Params:    0.10M\n",
            "FLOPs:     9.25M\n",
            "Inference: 1.55ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: PAMAP2\n",
            "======================================================================\n",
            "Train samples: 27190\n",
            "Test samples: 11653\n",
            "Input shape: (18, 100)\n",
            "Classes: 12\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 125,006 (0.13M)\n",
            "Trainable Parameters: 124,990 (0.12M)\n",
            "FLOPs: 12.46M\n",
            "Params (thop): 0.12M\n",
            "Inference Time: 1.55ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: PAMAP2\n",
            "======================================================================\n",
            "TRAIN - Loss: 1.9808 | Acc: 56.45%\n",
            "   CE: 1.4288 | Recon: 1.0046 | Vel: 0.0000 | Smooth: 4.9719\n",
            "TEST  - Loss: 1.0985 | Acc: 83.21% | F1: 83.09% | Prec: 84.51% | Rec: 83.21%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.28 GB\n",
            "New best model saved! Acc: 83.21% | F1: 83.09%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: PAMAP2\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.6639 | Acc: 93.47%\n",
            "   CE: 0.2305 | Recon: 0.8303 | Vel: 0.0000 | Smooth: 1.8289\n",
            "TEST  - Loss: 0.6725 | Acc: 92.62% | F1: 92.69% | Prec: 93.01% | Rec: 92.62%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.32 GB\n",
            "New best model saved! Acc: 92.62% | F1: 92.69%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: PAMAP2\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.4290 | Acc: 98.65%\n",
            "   CE: 0.0458 | Recon: 0.7594 | Vel: 0.0000 | Smooth: 0.3489\n",
            "TEST  - Loss: 0.6012 | Acc: 95.15% | F1: 95.16% | Prec: 95.19% | Rec: 95.15%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.32 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - PAMAP2\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[1119   10   11    1    1    0    1    1    2    5    2    0]\n",
            " [   3 1061   13    0    1    0    0    1    4   16   10    2]\n",
            " [   5    5 1097    4    1    0    0    6    2    5   14    0]\n",
            " [   0    0    8 1398    2    0    3    6    6    4    5    0]\n",
            " [   0    0    2    3  571    0    0    3    4    1    2    3]\n",
            " [   0    2    0    0    0  969    0    0    0    5   11    0]\n",
            " [   0    0    0    4    1    1 1109    1    3    3    5    2]\n",
            " [   2    2    5    7    1    1    3  661    8    4    6    3]\n",
            " [   0    2    8    8    2    0    0   15  581    9    4    2]\n",
            " [   0    8   12    1    2    5    2    5    5  971   40    1]\n",
            " [   0    3   29    5    2    2    3    2    5   27 1354    1]\n",
            " [   0    3    2    1    1    0    4    5    2    6    3  267]]\n",
            "Confusion matrix saved: confusion_matrix_PAMAP2.png\n",
            "t-SNE plot saved: tsne_PAMAP2.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  lying: 97.05%\n",
            "  sitting: 95.50%\n",
            "  standing: 96.31%\n",
            "  walking: 97.63%\n",
            "  running: 96.94%\n",
            "  cycling: 98.18%\n",
            "  Nordic walking: 98.23%\n",
            "  ascending stairs: 94.03%\n",
            "  descending stairs: 92.08%\n",
            "  vacuum cleaning: 92.30%\n",
            "  ironing: 94.49%\n",
            "  rope jumping: 90.82%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - PAMAP2\n",
            "======================================================================\n",
            "Accuracy:  95.75%\n",
            "F1 Score:  95.76%\n",
            "Precision: 95.78%\n",
            "Recall:    95.75%\n",
            "Params:    0.13M\n",
            "FLOPs:     12.46M\n",
            "Inference: 1.55ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: MHEALTH\n",
            "======================================================================\n",
            "Train samples: 9599\n",
            "Test samples: 4115\n",
            "Input shape: (21, 50)\n",
            "Classes: 12\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 129,329 (0.13M)\n",
            "Trainable Parameters: 129,313 (0.13M)\n",
            "FLOPs: 6.34M\n",
            "Params (thop): 0.13M\n",
            "Inference Time: 1.54ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: MHEALTH\n",
            "======================================================================\n",
            "TRAIN - Loss: 2.6782 | Acc: 30.24%\n",
            "   CE: 2.1529 | Recon: 1.0008 | Vel: 0.0000 | Smooth: 2.4895\n",
            "TEST  - Loss: 2.3173 | Acc: 46.10% | F1: 40.56% | Prec: 49.52% | Rec: 46.10%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.32 GB\n",
            "New best model saved! Acc: 46.10% | F1: 40.56%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: MHEALTH\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.3810 | Acc: 99.81%\n",
            "   CE: 0.0097 | Recon: 0.7328 | Vel: 0.0000 | Smooth: 0.4921\n",
            "TEST  - Loss: 0.3825 | Acc: 99.59% | F1: 99.59% | Prec: 99.59% | Rec: 99.59%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.32 GB\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: MHEALTH\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.3054 | Acc: 99.99%\n",
            "   CE: 0.0021 | Recon: 0.6050 | Vel: 0.0000 | Smooth: 0.0796\n",
            "TEST  - Loss: 0.3196 | Acc: 99.68% | F1: 99.68% | Prec: 99.68% | Rec: 99.68%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.32 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - MHEALTH\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[366   0   0   0   1   0   0   0   0   0   0   0]\n",
            " [  0 369   0   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0 369   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0 369   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0 364   0   0   2   0   0   0   0]\n",
            " [  0   0   0   1   0 338   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 353   0   0   0   0   0]\n",
            " [  0   0   0   0   0   1   0 350   1   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 369   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 368   1   0]\n",
            " [  0   0   0   0   0   0   0   0   0   3 366   0]\n",
            " [  0   0   0   0   0   0   0   0   0   0   0 123]]\n",
            "Confusion matrix saved: confusion_matrix_MHEALTH.png\n",
            "t-SNE plot saved: tsne_MHEALTH.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  Standing still: 99.73%\n",
            "  Sitting and relaxing: 100.00%\n",
            "  Lying down: 100.00%\n",
            "  Walking: 100.00%\n",
            "  Climbing stairs: 99.45%\n",
            "  Waist bends forward: 99.41%\n",
            "  Frontal elevation of arms: 100.00%\n",
            "  Knees bending: 99.43%\n",
            "  Cycling: 100.00%\n",
            "  Jogging: 99.73%\n",
            "  Running: 99.19%\n",
            "  Jump front & back: 100.00%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - MHEALTH\n",
            "======================================================================\n",
            "Accuracy:  99.73%\n",
            "F1 Score:  99.73%\n",
            "Precision: 99.73%\n",
            "Recall:    99.73%\n",
            "Params:    0.13M\n",
            "FLOPs:     6.34M\n",
            "Inference: 1.54ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: MobiAct\n",
            "======================================================================\n",
            "Train samples: 10882\n",
            "Test samples: 4665\n",
            "Input shape: (9, 100)\n",
            "Classes: 9\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 111,650 (0.11M)\n",
            "Trainable Parameters: 111,634 (0.11M)\n",
            "FLOPs: 11.92M\n",
            "Params (thop): 0.11M\n",
            "Inference Time: 1.53ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: MobiAct\n",
            "======================================================================\n",
            "TRAIN - Loss: 2.0460 | Acc: 50.06%\n",
            "   CE: 1.5130 | Recon: 0.9763 | Vel: 0.0000 | Smooth: 4.4864\n",
            "TEST  - Loss: 1.8868 | Acc: 62.98% | F1: 52.20% | Prec: 52.11% | Rec: 62.98%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.32 GB\n",
            "New best model saved! Acc: 62.98% | F1: 52.20%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: MobiAct\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.5415 | Acc: 98.04%\n",
            "   CE: 0.0723 | Recon: 0.9172 | Vel: 0.0000 | Smooth: 1.0585\n",
            "TEST  - Loss: 0.6078 | Acc: 96.38% | F1: 96.38% | Prec: 96.42% | Rec: 96.38%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.32 GB\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: MobiAct\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.4096 | Acc: 99.78%\n",
            "   CE: 0.0090 | Recon: 0.7944 | Vel: 0.0000 | Smooth: 0.3371\n",
            "TEST  - Loss: 0.5461 | Acc: 97.62% | F1: 97.61% | Prec: 97.61% | Rec: 97.62%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.32 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - MobiAct\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 115    0    0    0    5    2    2    4    2]\n",
            " [   2  124    0    0    0    0    1    0    0]\n",
            " [   1    0  412    1    0    0    4    2    0]\n",
            " [   1    0    3  407    0    0    5    0    0]\n",
            " [   4    1    0    0  128    0    0    0    0]\n",
            " [   0    0    0    0    1 1476    2    0    0]\n",
            " [   0    0    2    0    0    1  225    9   12]\n",
            " [   1    0    0    0    0    1   11  225    7]\n",
            " [   0    0    0    0    0    0    6    3 1457]]\n",
            "Confusion matrix saved: confusion_matrix_MobiAct.png\n",
            "t-SNE plot saved: tsne_MobiAct.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  CSI: 88.46%\n",
            "  CSO: 97.64%\n",
            "  JOG: 98.10%\n",
            "  JUM: 97.84%\n",
            "  SCH: 96.24%\n",
            "  STD: 99.80%\n",
            "  STN: 90.36%\n",
            "  STU: 91.84%\n",
            "  WAL: 99.39%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - MobiAct\n",
            "======================================================================\n",
            "Accuracy:  97.94%\n",
            "F1 Score:  97.94%\n",
            "Precision: 97.95%\n",
            "Recall:    97.94%\n",
            "Params:    0.11M\n",
            "FLOPs:     11.92M\n",
            "Inference: 1.53ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "TRAINING ON: MotionSense\n",
            "======================================================================\n",
            "Train samples: 16010\n",
            "Test samples: 4510\n",
            "Input shape: (12, 128)\n",
            "Classes: 6\n",
            "\n",
            "======================================================================\n",
            "MODEL ANALYSIS\n",
            "======================================================================\n",
            "Total Parameters: 115,586 (0.12M)\n",
            "Trainable Parameters: 115,570 (0.12M)\n",
            "FLOPs: 15.47M\n",
            "Params (thop): 0.12M\n",
            "Inference Time: 1.53ms\n",
            "\n",
            "======================================================================\n",
            "TRAINING STARTS\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "EPOCH 1/50 | Dataset: MotionSense\n",
            "======================================================================\n",
            "TRAIN - Loss: 1.7788 | Acc: 53.26%\n",
            "   CE: 1.2417 | Recon: 0.9608 | Vel: 0.0000 | Smooth: 5.6605\n",
            "TEST  - Loss: 0.9340 | Acc: 82.95% | F1: 81.44% | Prec: 81.97% | Rec: 82.95%\n",
            "LR: 0.000999\n",
            "GPU Memory: 0.32 GB\n",
            "New best model saved! Acc: 82.95% | F1: 81.44%\n",
            "\n",
            "======================================================================\n",
            "EPOCH 20/50 | Dataset: MotionSense\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.3496 | Acc: 99.33%\n",
            "   CE: 0.0287 | Recon: 0.6246 | Vel: 0.0000 | Smooth: 0.8590\n",
            "TEST  - Loss: 0.5794 | Acc: 92.88% | F1: 93.13% | Prec: 94.25% | Rec: 92.88%\n",
            "LR: 0.000655\n",
            "GPU Memory: 0.36 GB\n",
            "\n",
            "======================================================================\n",
            "EPOCH 40/50 | Dataset: MotionSense\n",
            "======================================================================\n",
            "TRAIN - Loss: 0.2619 | Acc: 99.97%\n",
            "   CE: 0.0016 | Recon: 0.5188 | Vel: 0.0000 | Smooth: 0.0964\n",
            "TEST  - Loss: 0.7125 | Acc: 93.61% | F1: 93.73% | Prec: 94.51% | Rec: 93.61%\n",
            "LR: 0.000096\n",
            "GPU Memory: 0.36 GB\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS - MotionSense\n",
            "======================================================================\n",
            "\n",
            "Confusion Matrix:\n",
            "[[ 293    0    0    0    5    9]\n",
            " [   2  111    0    0    0    0]\n",
            " [   9    0 1406    0    0    0]\n",
            " [   0    0    6  989    1    0]\n",
            " [  15   15    0    0  557   53]\n",
            " [  40    3    0    2   15  979]]\n",
            "Confusion matrix saved: confusion_matrix_MotionSense.png\n",
            "t-SNE plot saved: tsne_MotionSense.png\n",
            "\n",
            "Per-class Accuracy:\n",
            "  dws: 95.44%\n",
            "  jog: 98.23%\n",
            "  sit: 99.36%\n",
            "  std: 99.30%\n",
            "  ups: 87.03%\n",
            "  wlk: 94.23%\n",
            "\n",
            "======================================================================\n",
            "SUMMARY - MotionSense\n",
            "======================================================================\n",
            "Accuracy:  96.12%\n",
            "F1 Score:  96.15%\n",
            "Precision: 96.33%\n",
            "Recall:    96.12%\n",
            "Params:    0.12M\n",
            "FLOPs:     15.47M\n",
            "Inference: 1.53ms\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "OVERALL RESULTS\n",
            "======================================================================\n",
            "\n",
            "\n",
            "    Dataset  Accuracy        F1  Precision    Recall  Params (M)  FLOPs (M)  Inference (ms)\n",
            "    UCI-HAR 87.818120 87.782749  87.891915 87.818120    0.282742   1.990912        1.479876\n",
            "      WISDM 99.055910 99.056377  99.060118 99.055910    0.102617   9.254912        1.554921\n",
            "     PAMAP2 95.752167 95.759665  95.783025 95.752167    0.125006  12.458240        1.550584\n",
            "    MHEALTH 99.732685 99.732615  99.733008 99.732685    0.129329   6.336128        1.535749\n",
            "    MobiAct 97.942122 97.942445  97.950920 97.942122    0.111650  11.918336        1.533730\n",
            "MotionSense 96.119734 96.145825  96.333395 96.119734    0.115586  15.467264        1.534336\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       Dataset   Accuracy         F1  Precision     Recall  Params (M)  \\\n",
              "0      UCI-HAR  87.818120  87.782749  87.891915  87.818120    0.282742   \n",
              "1        WISDM  99.055910  99.056377  99.060118  99.055910    0.102617   \n",
              "2       PAMAP2  95.752167  95.759665  95.783025  95.752167    0.125006   \n",
              "3      MHEALTH  99.732685  99.732615  99.733008  99.732685    0.129329   \n",
              "4      MobiAct  97.942122  97.942445  97.950920  97.942122    0.111650   \n",
              "5  MotionSense  96.119734  96.145825  96.333395  96.119734    0.115586   \n",
              "\n",
              "   FLOPs (M)  Inference (ms)  \n",
              "0   1.990912        1.479876  \n",
              "1   9.254912        1.554921  \n",
              "2  12.458240        1.550584  \n",
              "3   6.336128        1.535749  \n",
              "4  11.918336        1.533730  \n",
              "5  15.467264        1.534336  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c37529f-28ef-49bb-a146-5d4aae031eac\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataset</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Params (M)</th>\n",
              "      <th>FLOPs (M)</th>\n",
              "      <th>Inference (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>UCI-HAR</td>\n",
              "      <td>87.818120</td>\n",
              "      <td>87.782749</td>\n",
              "      <td>87.891915</td>\n",
              "      <td>87.818120</td>\n",
              "      <td>0.282742</td>\n",
              "      <td>1.990912</td>\n",
              "      <td>1.479876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WISDM</td>\n",
              "      <td>99.055910</td>\n",
              "      <td>99.056377</td>\n",
              "      <td>99.060118</td>\n",
              "      <td>99.055910</td>\n",
              "      <td>0.102617</td>\n",
              "      <td>9.254912</td>\n",
              "      <td>1.554921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PAMAP2</td>\n",
              "      <td>95.752167</td>\n",
              "      <td>95.759665</td>\n",
              "      <td>95.783025</td>\n",
              "      <td>95.752167</td>\n",
              "      <td>0.125006</td>\n",
              "      <td>12.458240</td>\n",
              "      <td>1.550584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MHEALTH</td>\n",
              "      <td>99.732685</td>\n",
              "      <td>99.732615</td>\n",
              "      <td>99.733008</td>\n",
              "      <td>99.732685</td>\n",
              "      <td>0.129329</td>\n",
              "      <td>6.336128</td>\n",
              "      <td>1.535749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MobiAct</td>\n",
              "      <td>97.942122</td>\n",
              "      <td>97.942445</td>\n",
              "      <td>97.950920</td>\n",
              "      <td>97.942122</td>\n",
              "      <td>0.111650</td>\n",
              "      <td>11.918336</td>\n",
              "      <td>1.533730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MotionSense</td>\n",
              "      <td>96.119734</td>\n",
              "      <td>96.145825</td>\n",
              "      <td>96.333395</td>\n",
              "      <td>96.119734</td>\n",
              "      <td>0.115586</td>\n",
              "      <td>15.467264</td>\n",
              "      <td>1.534336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c37529f-28ef-49bb-a146-5d4aae031eac')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7c37529f-28ef-49bb-a146-5d4aae031eac button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7c37529f-28ef-49bb-a146-5d4aae031eac');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6e0abdcc-7f7c-43ac-b362-c883ed270199\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6e0abdcc-7f7c-43ac-b362-c883ed270199')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6e0abdcc-7f7c-43ac-b362-c883ed270199 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    main()\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Dataset\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"UCI-HAR\",\n          \"WISDM\",\n          \"MotionSense\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.336652510465597,\n        \"min\": 87.81812012215812,\n        \"max\": 99.73268529769138,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          87.81812012215812,\n          99.05590975968612,\n          96.11973392461198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.350168479102497,\n        \"min\": 87.78274895543609,\n        \"max\": 99.73261452669377,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          87.78274895543609,\n          99.05637677691828,\n          96.14582459402165\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.310700290436742,\n        \"min\": 87.8919148410077,\n        \"max\": 99.73300762092553,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          87.8919148410077,\n          99.06011769341002,\n          96.33339532383354\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.336652510465597,\n        \"min\": 87.81812012215812,\n        \"max\": 99.73268529769138,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          87.81812012215812,\n          99.05590975968612,\n          96.11973392461198\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Params (M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06839642184987944,\n        \"min\": 0.102617,\n        \"max\": 0.282742,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.282742,\n          0.102617,\n          0.115586\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"FLOPs (M)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.829784939991704,\n        \"min\": 1.990912,\n        \"max\": 15.467264,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.990912,\n          9.254912,\n          15.467264\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Inference (ms)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02686566220122845,\n        \"min\": 1.4798760414123535,\n        \"max\": 1.5549206733703613,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.4798760414123535,\n          1.5549206733703613,\n          1.5343356132507324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results saved to: imf_results.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.manifold import TSNE\n",
        "from collections import Counter\n",
        "import os\n",
        "import time\n",
        "import re\n",
        "from glob import glob\n",
        "import glob as glob_module\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gc\n",
        "\n",
        "try:\n",
        "    from thop import profile\n",
        "    THOP_AVAILABLE = True\n",
        "except ImportError:\n",
        "    print(\"Warning: thop not available. Install with: pip install thop\")\n",
        "    THOP_AVAILABLE = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.enabled = True\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "WEIGHT_DECAY = 1e-4\n",
        "NUM_WORKERS = 4\n",
        "\n",
        "HIDDEN_DIM = 128\n",
        "LATENT_DIM = 64\n",
        "NUM_FREQUENCIES = 16\n",
        "SIREN_OMEGA = 30.0\n",
        "NUM_SIREN_LAYERS = 3\n",
        "\n",
        "RANDOM_SAMPLING = True\n",
        "SAMPLING_RATIO = 0.5\n",
        "DERIVATIVE_SUPERVISION = False\n",
        "DOWNSAMPLE_EXPERIMENT = True\n",
        "DOWNSAMPLE_POINTS = 32\n",
        "\n",
        "USE_AMP = True\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Batch Size: {BATCH_SIZE} (Effective: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS})\")\n",
        "print(f\"Gradient Accumulation Steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
        "print(f\"Epochs: {EPOCHS}\")\n",
        "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
        "print(f\"Hidden Dim: {HIDDEN_DIM} | Latent Dim: {LATENT_DIM}\")\n",
        "print(f\"SIREN Layers: {NUM_SIREN_LAYERS} | Frequencies: {NUM_FREQUENCIES}\")\n",
        "print(f\"Mixed Precision: {USE_AMP}\")\n",
        "print(f\"Num Workers: {NUM_WORKERS}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "class UCIHARDataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.labels = torch.LongTensor(labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx], self.labels[idx]\n",
        "\n",
        "\n",
        "def read_txt_matrix(file_path):\n",
        "    return np.loadtxt(file_path)\n",
        "\n",
        "\n",
        "def load_uci_har(root_path='/content/drive/MyDrive/HAR_Dataset/UCI'):\n",
        "    print(f\"\\n[UCI-HAR] Loading from: {root_path}\")\n",
        "    UCI_CHANNELS_PREFIX = [\n",
        "        \"total_acc_x_\", \"total_acc_y_\", \"total_acc_z_\",\n",
        "        \"body_acc_x_\", \"body_acc_y_\", \"body_acc_z_\",\n",
        "        \"body_gyro_x_\", \"body_gyro_y_\", \"body_gyro_z_\",\n",
        "    ]\n",
        "    def load_split(split):\n",
        "        channels = []\n",
        "        for prefix in UCI_CHANNELS_PREFIX:\n",
        "            file_path = os.path.join(root_path, f\"{prefix}{split}.txt\")\n",
        "            print(f\"  Loading: {os.path.basename(file_path)}\")\n",
        "            if not os.path.exists(file_path):\n",
        "                raise FileNotFoundError(f\"File not found: {file_path}\")\n",
        "            channels.append(read_txt_matrix(file_path))\n",
        "        X = np.stack(channels, axis=1)\n",
        "        y = read_txt_matrix(os.path.join(root_path, f\"y_{split}.txt\")).astype(int) - 1\n",
        "        return X, y\n",
        "\n",
        "    X_train, y_train = load_split('train')\n",
        "    X_test, y_test = load_split('test')\n",
        "    X_train = X_train.transpose(0, 2, 1)\n",
        "    X_test = X_test.transpose(0, 2, 1)\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train_flat)\n",
        "    X_train_flat = scaler.transform(X_train_flat)\n",
        "    X_test_flat = scaler.transform(X_test_flat)\n",
        "    X_train = X_train_flat.reshape(X_train.shape)\n",
        "    X_test = X_test_flat.reshape(X_test.shape)\n",
        "    activity_names = ['Walking', 'Walking Upstairs', 'Walking Downstairs', 'Sitting', 'Standing', 'Laying']\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train.astype(np.int64), X_test, y_test.astype(np.int64), activity_names\n",
        "\n",
        "\n",
        "def load_wisdm_data(dataset_path=\"/content/drive/MyDrive/HAR_Dataset/WISDM\"):\n",
        "    print(f\"\\n[WISDM] Loading from: {dataset_path}\")\n",
        "    if os.path.isfile(dataset_path):\n",
        "        file_paths = [dataset_path]\n",
        "    else:\n",
        "        possible_files = ['WISDM_ar_v1.1_raw.txt', 'WISDM_ar_v1.1_trans.arff', 'wisdm-dataset.txt', 'actitracker_raw.txt']\n",
        "        file_paths = []\n",
        "        for filename in possible_files:\n",
        "            full_path = os.path.join(dataset_path, filename)\n",
        "            if os.path.exists(full_path):\n",
        "                file_paths.append(full_path)\n",
        "                print(f\"  Found: {filename}\")\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    all_data = []\n",
        "    for file_path in file_paths:\n",
        "        print(f\"  Processing: {os.path.basename(file_path)}\")\n",
        "        with open(file_path, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "        cleaned_data = []\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.rstrip(';').rstrip(',')\n",
        "            if ',' in line:\n",
        "                parts = line.split(',')\n",
        "            elif ';' in line:\n",
        "                parts = line.split(';')\n",
        "            else:\n",
        "                continue\n",
        "            if len(parts) < 6:\n",
        "                continue\n",
        "            try:\n",
        "                user = parts[0].strip()\n",
        "                activity = parts[1].strip()\n",
        "                timestamp = parts[2].strip()\n",
        "                x_str = parts[3].strip()\n",
        "                y_str = parts[4].strip()\n",
        "                z_str = parts[5].strip()\n",
        "                if ';' in x_str:\n",
        "                    x_str = x_str.split(';')[0]\n",
        "                if ';' in y_str:\n",
        "                    y_str = y_str.split(';')[0]\n",
        "                if ';' in z_str:\n",
        "                    z_str = z_str.split(';')[0]\n",
        "                x = float(x_str)\n",
        "                y = float(y_str)\n",
        "                z = float(z_str)\n",
        "                cleaned_data.append([user, activity, timestamp, x, y, z])\n",
        "            except (ValueError, IndexError):\n",
        "                continue\n",
        "        if cleaned_data:\n",
        "            df = pd.DataFrame(cleaned_data, columns=['user', 'activity', 'timestamp', 'x', 'y', 'z'])\n",
        "            df['x'] = pd.to_numeric(df['x'], errors='coerce')\n",
        "            df['y'] = pd.to_numeric(df['y'], errors='coerce')\n",
        "            df['z'] = pd.to_numeric(df['z'], errors='coerce')\n",
        "            df = df.dropna()\n",
        "            all_data.append(df)\n",
        "\n",
        "    if not all_data:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    combined_df = pd.concat(all_data, ignore_index=True)\n",
        "    combined_df = combined_df.dropna()\n",
        "    combined_df = combined_df[combined_df['activity'].str.strip() != '']\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    groups = combined_df.groupby(['user', 'activity']) if 'user' in combined_df.columns else combined_df.groupby(['activity'])\n",
        "    window_size = 80\n",
        "    step = 40\n",
        "    for group_name, group_data in groups:\n",
        "        activity = group_name[-1] if isinstance(group_name, tuple) else group_name\n",
        "        acc_data = group_data[['x', 'y', 'z']].values.astype(np.float32)\n",
        "        if len(acc_data) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(acc_data):\n",
        "            window_data = acc_data[start:start + window_size, :]\n",
        "            all_windows.append(window_data)\n",
        "            all_labels.append(activity)\n",
        "            start += step\n",
        "\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_windowed = X_windowed.transpose(0, 2, 1)\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    class_names = [str(label) for label in label_encoder.classes_]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, class_names\n",
        "\n",
        "\n",
        "def load_pamap2_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/PAMAP2\"):\n",
        "    print(f\"\\n[PAMAP2] Loading from: {dataset_dir}\")\n",
        "    file_paths = sorted(glob(os.path.join(dataset_dir, 'Protocol', 'subject*.dat')))\n",
        "    optional_path = os.path.join(dataset_dir, 'Optional')\n",
        "    if os.path.exists(optional_path):\n",
        "        file_paths += sorted(glob(os.path.join(optional_path, 'subject*.dat')))\n",
        "    if not file_paths:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    print(f\"  Found {len(file_paths)} subject files\")\n",
        "\n",
        "    activity_labels = [\n",
        "        \"lying\", \"sitting\", \"standing\", \"walking\", \"running\", \"cycling\",\n",
        "        \"Nordic walking\", \"ascending stairs\", \"descending stairs\",\n",
        "        \"vacuum cleaning\", \"ironing\", \"rope jumping\"\n",
        "    ]\n",
        "    label_to_activity_idx = {\n",
        "        1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 12: 7, 13: 8, 16: 9, 17: 10, 24: 11\n",
        "    }\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 100\n",
        "    step = 50\n",
        "    for file_path in file_paths:\n",
        "        print(f\"  Processing: {os.path.basename(file_path)}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, na_values='NaN')\n",
        "        except:\n",
        "            continue\n",
        "        df_cleaned = df.ffill().bfill()\n",
        "        if df_cleaned.empty:\n",
        "            continue\n",
        "        labels = df_cleaned.iloc[:, 1].values.astype(int)\n",
        "        all_sensor_cols = list(range(4, 10)) + list(range(21, 27)) + list(range(38, 44))\n",
        "        if df_cleaned.shape[1] < max(all_sensor_cols) + 1:\n",
        "            continue\n",
        "        features = df_cleaned.iloc[:, all_sensor_cols].values.astype(np.float32)\n",
        "        valid_indices = np.where(np.isin(labels, list(label_to_activity_idx.keys())))[0]\n",
        "        if len(valid_indices) == 0:\n",
        "            continue\n",
        "        features = features[valid_indices, :]\n",
        "        labels = labels[valid_indices]\n",
        "        if len(features) < window_size:\n",
        "            continue\n",
        "        start = 0\n",
        "        while start + window_size <= len(features):\n",
        "            window_data = features[start : start + window_size, :]\n",
        "            window_labels_raw = labels[start : start + window_size]\n",
        "            most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "            if most_common_label in label_to_activity_idx:\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(label_to_activity_idx[most_common_label])\n",
        "            start += step\n",
        "\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_windowed = X_windowed.transpose(0, 2, 1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "def load_mhealth_data(dataset_dir=\"/content/drive/MyDrive/HAR_Dataset/MHEALTH\"):\n",
        "    print(f\"\\n[MHEALTH] Loading from: {dataset_dir}\")\n",
        "    if not os.path.exists(dataset_dir):\n",
        "        return None, None, None, None, None\n",
        "    subject_files = sorted([\n",
        "        os.path.join(dataset_dir, f)\n",
        "        for f in os.listdir(dataset_dir)\n",
        "        if f.startswith(\"mHealth_subject\") and f.endswith(\".log\")\n",
        "    ])\n",
        "    if not subject_files:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    print(f\"  Found {len(subject_files)} subject files\")\n",
        "\n",
        "    all_windows = []\n",
        "    all_labels = []\n",
        "    window_size = 50\n",
        "    step = 25\n",
        "    for file_path in subject_files:\n",
        "        print(f\"  Processing: {os.path.basename(file_path)}\")\n",
        "        try:\n",
        "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python', dtype=np.float32)\n",
        "            df = df.ffill().bfill()\n",
        "            if df.shape[1] < 24:\n",
        "                continue\n",
        "            labels = df.iloc[:, 23].values.astype(int)\n",
        "            imu_cols = [0, 1, 2] + list(range(5, 23))\n",
        "            features = df.iloc[:, imu_cols].values\n",
        "            valid_indices = np.where(labels != 0)[0]\n",
        "            if len(valid_indices) == 0:\n",
        "                continue\n",
        "            features = features[valid_indices, :]\n",
        "            labels = labels[valid_indices]\n",
        "            if len(features) < window_size:\n",
        "                continue\n",
        "            start = 0\n",
        "            while start + window_size <= len(features):\n",
        "                window_data = features[start : start + window_size, :]\n",
        "                window_labels_raw = labels[start : start + window_size]\n",
        "                most_common_label = Counter(window_labels_raw).most_common(1)[0][0]\n",
        "                all_windows.append(window_data)\n",
        "                all_labels.append(most_common_label)\n",
        "                start += step\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(all_labels)\n",
        "    X_windowed = np.array(all_windows, dtype=np.float32)\n",
        "    scaler = StandardScaler()\n",
        "    X_windowed_flat = X_windowed.reshape(X_windowed.shape[0], -1)\n",
        "    X_windowed_flat = scaler.fit_transform(X_windowed_flat)\n",
        "    X_windowed = X_windowed_flat.reshape(X_windowed.shape)\n",
        "    X_windowed = X_windowed.transpose(0, 2, 1)\n",
        "    mhealth_activity_mapping = {\n",
        "        1: 'Standing still', 2: 'Sitting and relaxing', 3: 'Lying down', 4: 'Walking',\n",
        "        5: 'Climbing stairs', 6: 'Waist bends forward', 7: 'Frontal elevation of arms',\n",
        "        8: 'Knees bending', 9: 'Cycling', 10: 'Jogging', 11: 'Running', 12: 'Jump front & back'\n",
        "    }\n",
        "    activity_labels = []\n",
        "    class_names = list(label_encoder.classes_)\n",
        "    for encoded_idx in range(len(class_names)):\n",
        "        original_label = class_names[encoded_idx]\n",
        "        activity_labels.append(mhealth_activity_mapping.get(original_label, f\"Unknown_Activity_{original_label}\"))\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_labels\n",
        "\n",
        "\n",
        "def slide_window(data, w_s, stride):\n",
        "    windows = []\n",
        "    start = 0\n",
        "    while start + w_s <= len(data):\n",
        "        windows.append(data[start:start + w_s, :])\n",
        "        start += stride\n",
        "    if not windows:\n",
        "        return np.array([])\n",
        "    return np.array(windows)\n",
        "\n",
        "\n",
        "def load_mobiact_sensor_file(path):\n",
        "    data = []\n",
        "    try:\n",
        "        with open(path, 'r') as f:\n",
        "            in_data_section = False\n",
        "            for line in f:\n",
        "                if line.startswith('@DATA'):\n",
        "                    in_data_section = True\n",
        "                    continue\n",
        "                if not in_data_section:\n",
        "                    continue\n",
        "                parts = line.strip().split(',')\n",
        "                if len(parts) == 4:\n",
        "                    try:\n",
        "                        data.append([float(p) for p in parts])\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "    except Exception as e:\n",
        "        return None\n",
        "    if not data:\n",
        "        return None\n",
        "    return np.array(data, dtype=np.float32)\n",
        "\n",
        "\n",
        "def load_mobiact_data(data_path, w_s=100, stride=50):\n",
        "    print(f\"\\n[MobiAct] Loading from: {data_path}\")\n",
        "    ADL_CODES = ['STD', 'WAL', 'JOG', 'JUM', 'STU', 'STN', 'SCH', 'CSI', 'CSO']\n",
        "    ALL_ACTIVITIES = ADL_CODES\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(ALL_ACTIVITIES)\n",
        "    activity_names = list(label_encoder.classes_)\n",
        "    subject_dirs = sorted(glob_module.glob(os.path.join(data_path, 'sub*')))\n",
        "    subjects_to_use = []\n",
        "    for sub_dir in subject_dirs:\n",
        "        if os.path.isdir(os.path.join(sub_dir, 'ADL')) and os.path.isdir(os.path.join(sub_dir, 'FALLS')):\n",
        "            subjects_to_use.append(os.path.basename(sub_dir))\n",
        "\n",
        "    print(f\"  Found {len(subjects_to_use)} subjects\")\n",
        "\n",
        "    all_data_for_scaler = []\n",
        "    all_windows, all_labels, all_subjects = [], [], []\n",
        "    temp_data_store = []\n",
        "    for sub_name in subjects_to_use:\n",
        "        print(f\"  Processing subject: {sub_name}\")\n",
        "        subject_id_match = re.search(r'(\\d+)', sub_name)\n",
        "        if not subject_id_match:\n",
        "            continue\n",
        "        subject_id = int(subject_id_match.group(0))\n",
        "        for act_type_folder in ['ADL']:\n",
        "            act_folders_path = os.path.join(data_path, sub_name, act_type_folder, '*')\n",
        "            for act_folder_path in glob_module.glob(act_folders_path):\n",
        "                act_code = os.path.basename(act_folder_path)\n",
        "                if act_code not in ALL_ACTIVITIES:\n",
        "                    continue\n",
        "                label = label_encoder.transform([act_code])[0]\n",
        "                trial_files = glob_module.glob(os.path.join(act_folder_path, f'{act_code}_acc_{subject_id}_*.txt'))\n",
        "                trials = sorted(list(set([f.split('_')[-1].split('.')[0] for f in trial_files])))\n",
        "                for trial in trials:\n",
        "                    acc_file = os.path.join(act_folder_path, f'{act_code}_acc_{subject_id}_{trial}.txt')\n",
        "                    gyro_file = os.path.join(act_folder_path, f'{act_code}_gyro_{subject_id}_{trial}.txt')\n",
        "                    ori_file = os.path.join(act_folder_path, f'{act_code}_ori_{subject_id}_{trial}.txt')\n",
        "                    if not all(os.path.exists(f) for f in [acc_file, gyro_file, ori_file]):\n",
        "                        continue\n",
        "                    data_acc = load_mobiact_sensor_file(acc_file)\n",
        "                    data_gyro = load_mobiact_sensor_file(gyro_file)\n",
        "                    data_ori = load_mobiact_sensor_file(ori_file)\n",
        "                    if any(d is None for d in [data_acc, data_gyro, data_ori]):\n",
        "                        continue\n",
        "                    L = min(len(data_acc), len(data_gyro), len(data_ori))\n",
        "                    if L < w_s:\n",
        "                        continue\n",
        "                    combined_data = np.hstack((data_acc[:L, 1:], data_gyro[:L, 1:], data_ori[:L, 1:]))\n",
        "                    combined_data = combined_data.astype(np.float32)\n",
        "                    combined_data = pd.DataFrame(combined_data).ffill().bfill().values\n",
        "                    if np.isnan(combined_data).any():\n",
        "                        continue\n",
        "                    all_data_for_scaler.append(combined_data)\n",
        "                    temp_data_store.append({\n",
        "                        'data': combined_data,\n",
        "                        'label': label,\n",
        "                        'subject': subject_id\n",
        "                    })\n",
        "\n",
        "    if not all_data_for_scaler:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    scaler = StandardScaler().fit(np.vstack(all_data_for_scaler))\n",
        "    for item in temp_data_store:\n",
        "        scaled_data = scaler.transform(item['data'])\n",
        "        scaled_data = np.nan_to_num(scaled_data)\n",
        "        windows = slide_window(scaled_data, w_s, stride)\n",
        "        if windows.shape[0] > 0:\n",
        "            all_windows.append(windows)\n",
        "            all_labels.extend([item['label']] * windows.shape[0])\n",
        "            all_subjects.extend([item['subject']] * windows.shape[0])\n",
        "\n",
        "    if not all_windows:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    X_windowed = np.vstack(all_windows).astype(np.float32)\n",
        "    X_windowed = np.transpose(X_windowed, (0, 2, 1))\n",
        "    y_encoded = np.array(all_labels, dtype=int)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_windowed, y_encoded, test_size=0.3, stratify=y_encoded, random_state=42)\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "\n",
        "class MotionSenseLoader:\n",
        "    def __init__(self, frame_len, feature_name, N_classes):\n",
        "        self.feature_names = feature_name\n",
        "        self.N_Feature = len(feature_name)\n",
        "        self.frame_length = frame_len\n",
        "        self.hop_size = frame_len//2\n",
        "        self.N_classes = N_classes\n",
        "        self.label_encoder = OneHotEncoder(sparse_output=False)\n",
        "\n",
        "    def framing(self, signal):\n",
        "        shape = ((signal.shape[0] - self.frame_length) // self.hop_size + 1, self.frame_length)\n",
        "        strides = (signal.strides[0] * self.hop_size, signal.strides[0])\n",
        "        return np.lib.stride_tricks.as_strided(signal, shape=shape, strides=strides)\n",
        "\n",
        "    def create_label(self, label):\n",
        "        return self.label_encoder.fit_transform(label)\n",
        "\n",
        "    def load_trainings_data(self, files, label_frame):\n",
        "        label = self.create_label(label_frame)\n",
        "        self.trainings_data, self.trainings_label = self.load_data(files, label)\n",
        "\n",
        "    def load_validation_data(self, files, label_frame):\n",
        "        label = self.label_encoder.transform(label_frame)\n",
        "        self.validation_data, self.validation_label = self.load_data(files, label)\n",
        "\n",
        "    def load_data(self, files, label):\n",
        "        feature_matrix, label_matrix = None, None\n",
        "        for i in range(len(files)):\n",
        "            try:\n",
        "                tmp_data = pd.read_csv(files[i], engine='python')\n",
        "            except:\n",
        "                continue\n",
        "            N_Blocks = 1+(np.shape(tmp_data)[0]-self.frame_length)//self.hop_size\n",
        "            if N_Blocks <= 0:\n",
        "                continue\n",
        "            tmp_feature_mat = np.zeros((N_Blocks, self.frame_length, self.N_Feature))\n",
        "            tmp_label_vec = np.zeros((N_Blocks, self.N_classes))\n",
        "            for j in range(N_Blocks):\n",
        "                tmp_label_vec[j, :] = label[i, :]\n",
        "            for idf, feat in enumerate(self.feature_names):\n",
        "                frame_matrix = self.framing(tmp_data[feat].to_numpy())\n",
        "                tmp_feature_mat[:, :, idf] = frame_matrix[:N_Blocks]\n",
        "            if feature_matrix is None:\n",
        "                feature_matrix = tmp_feature_mat\n",
        "                label_matrix = tmp_label_vec\n",
        "            else:\n",
        "                feature_matrix = np.append(feature_matrix, tmp_feature_mat, axis=0)\n",
        "                label_matrix = np.append(label_matrix, tmp_label_vec, axis=0)\n",
        "        return feature_matrix, label_matrix\n",
        "\n",
        "\n",
        "def load_motionsense_data(root_path='/content/drive/MyDrive/HAR_Dataset/MOTIONSENSE'):\n",
        "    print(f\"\\n[MotionSense] Loading from: {root_path}\")\n",
        "    files, label = [], []\n",
        "    for dirname, _, filenames in os.walk(root_path):\n",
        "        for filename in filenames:\n",
        "            if filename.endswith('.csv') and not filename.startswith('.'):\n",
        "                full_path = os.path.join(dirname, filename)\n",
        "                if 'sub_' in filename:\n",
        "                    files.append(full_path)\n",
        "                    parent_dir = os.path.basename(os.path.dirname(full_path))\n",
        "                    if '_' in parent_dir:\n",
        "                        label.append(parent_dir.split('_')[0])\n",
        "                    else:\n",
        "                        files.pop()\n",
        "    if not files:\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    print(f\"  Found {len(files)} CSV files\")\n",
        "\n",
        "    label_frame = pd.DataFrame(label, columns=['act'])\n",
        "    files_train, files_valid, y_train_raw, y_valid_raw = train_test_split(files, label_frame, test_size=0.2, random_state=0)\n",
        "    Feature = ['attitude.roll','attitude.pitch','attitude.yaw','gravity.x','gravity.y','gravity.z',\n",
        "               'rotationRate.x','rotationRate.y','rotationRate.z','userAcceleration.x','userAcceleration.y','userAcceleration.z']\n",
        "    N_classes = 6\n",
        "    loader = MotionSenseLoader(128, Feature, N_classes)\n",
        "    print(f\"  Processing training files...\")\n",
        "    loader.load_trainings_data(files_train, y_train_raw)\n",
        "    print(f\"  Processing validation files...\")\n",
        "    loader.load_validation_data(files_valid, y_valid_raw)\n",
        "    X_train = loader.trainings_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    X_test = loader.validation_data.astype(np.float32).transpose(0, 2, 1)\n",
        "    y_train = np.argmax(loader.trainings_label, axis=1)\n",
        "    y_test = np.argmax(loader.validation_label, axis=1)\n",
        "    activity_names = list(loader.label_encoder.categories_[0])\n",
        "    print(f\"  Train: {X_train.shape}, Test: {X_test.shape}\")\n",
        "    return X_train, y_train, X_test, y_test, activity_names\n",
        "\n",
        "\n",
        "class FourierFeatureMapping(nn.Module):\n",
        "    def __init__(self, num_frequencies, scale=1.0):\n",
        "        super().__init__()\n",
        "        self.num_frequencies = num_frequencies\n",
        "        self.scale = scale\n",
        "        self.B = nn.Parameter(\n",
        "            torch.randn(1, num_frequencies) * scale,\n",
        "            requires_grad=False\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_proj = 2 * np.pi * x @ self.B\n",
        "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
        "\n",
        "\n",
        "class SirenLayer(nn.Module):\n",
        "    def __init__(self, in_features, out_features, omega=30.0, is_first=False):\n",
        "        super().__init__()\n",
        "        self.omega = omega\n",
        "        self.is_first = is_first\n",
        "        self.linear = nn.Linear(in_features, out_features)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        with torch.no_grad():\n",
        "            if self.is_first:\n",
        "                self.linear.weight.uniform_(-1 / self.linear.in_features,\n",
        "                                             1 / self.linear.in_features)\n",
        "            else:\n",
        "                self.linear.weight.uniform_(\n",
        "                    -np.sqrt(6 / self.linear.in_features) / self.omega,\n",
        "                    np.sqrt(6 / self.linear.in_features) / self.omega\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sin(self.omega * self.linear(x))\n",
        "\n",
        "\n",
        "class ImplicitMotionField(nn.Module):\n",
        "    def __init__(self, latent_dim, hidden_dim, output_dim, num_layers=3):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.fourier_mapping = FourierFeatureMapping(NUM_FREQUENCIES, scale=10.0)\n",
        "\n",
        "        input_dim = latent_dim + 2 * NUM_FREQUENCIES\n",
        "\n",
        "        self.siren1 = SirenLayer(input_dim, hidden_dim, SIREN_OMEGA, is_first=True)\n",
        "        self.siren2 = SirenLayer(hidden_dim, hidden_dim, SIREN_OMEGA)\n",
        "        self.siren3 = SirenLayer(hidden_dim, hidden_dim, SIREN_OMEGA)\n",
        "\n",
        "        self.final_layer = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            self.final_layer.weight.uniform_(\n",
        "                -np.sqrt(6 / hidden_dim) / SIREN_OMEGA,\n",
        "                np.sqrt(6 / hidden_dim) / SIREN_OMEGA\n",
        "            )\n",
        "\n",
        "    def forward(self, latent_code, time_coords):\n",
        "        batch_size, num_samples, _ = time_coords.shape\n",
        "        latent_expanded = latent_code.unsqueeze(1).expand(-1, num_samples, -1)\n",
        "        time_features = self.fourier_mapping(time_coords.reshape(-1, 1))\n",
        "        time_features = time_features.reshape(batch_size, num_samples, -1)\n",
        "\n",
        "        x = torch.cat([latent_expanded, time_features], dim=-1)\n",
        "        x = x.reshape(-1, x.shape[-1])\n",
        "\n",
        "        x = self.siren1(x)\n",
        "        x = self.siren2(x)\n",
        "        x = self.siren3(x)\n",
        "        x = self.final_layer(x)\n",
        "\n",
        "        x = x.reshape(batch_size, num_samples, -1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class LightweightEncoder(nn.Module):\n",
        "    def __init__(self, input_channels, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(input_channels, 32, kernel_size=5, padding=2)\n",
        "        self.bn1 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
        "        self.bn2 = nn.BatchNorm1d(64)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm1d(128)\n",
        "\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
        "\n",
        "        self.fc_latent = nn.Linear(128, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = torch.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = torch.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "\n",
        "        x = self.gap(x)\n",
        "        x = x.squeeze(-1)\n",
        "\n",
        "        latent = self.fc_latent(x)\n",
        "        return latent\n",
        "\n",
        "\n",
        "class MotionStatisticsExtractor(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "    def forward(self, motion_field):\n",
        "        mean = motion_field.mean(dim=2)\n",
        "        std = motion_field.std(dim=2)\n",
        "        min_val = motion_field.min(dim=2)[0]\n",
        "        max_val = motion_field.max(dim=2)[0]\n",
        "\n",
        "        with autocast('cuda', enabled=False):\n",
        "            motion_field_fp32 = motion_field.float()\n",
        "            fft = torch.fft.rfft(motion_field_fp32, dim=2)\n",
        "            fft_mag = torch.abs(fft)\n",
        "            fft_features = fft_mag[:, :, :5].flatten(1)\n",
        "\n",
        "        features = torch.cat([mean, std, min_val, max_val, fft_features], dim=1)\n",
        "        return features\n",
        "\n",
        "\n",
        "class LightweightIMF(nn.Module):\n",
        "    def __init__(self, input_channels, hidden_dim, latent_dim, num_classes, seq_length):\n",
        "        super().__init__()\n",
        "        self.seq_length = seq_length\n",
        "        self.input_channels = input_channels\n",
        "\n",
        "        self.encoder = LightweightEncoder(input_channels, latent_dim)\n",
        "\n",
        "        self.motion_field = ImplicitMotionField(\n",
        "            latent_dim=latent_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            output_dim=input_channels,\n",
        "            num_layers=3\n",
        "        )\n",
        "\n",
        "        self.stat_extractor = MotionStatisticsExtractor(input_channels)\n",
        "\n",
        "        stat_dim = input_channels * 4 + input_channels * 5\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(latent_dim + stat_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, sample_times=None, num_samples=None, return_latent=False):\n",
        "        batch_size = x.shape[0]\n",
        "        latent = self.encoder(x)\n",
        "\n",
        "        if sample_times is None:\n",
        "            if num_samples is None:\n",
        "                num_samples = self.seq_length\n",
        "            sample_times = torch.linspace(0, 1, num_samples, device=x.device)\n",
        "            sample_times = sample_times.unsqueeze(0).unsqueeze(-1)\n",
        "            sample_times = sample_times.expand(batch_size, -1, -1)\n",
        "\n",
        "        motion_recon = self.motion_field(latent, sample_times)\n",
        "        motion_recon = motion_recon.permute(0, 2, 1)\n",
        "\n",
        "        motion_stats = self.stat_extractor(motion_recon)\n",
        "        combined_features = torch.cat([latent, motion_stats], dim=1)\n",
        "        logits = self.classifier(combined_features)\n",
        "\n",
        "        if return_latent:\n",
        "            return logits, motion_recon, latent\n",
        "        return logits, motion_recon, latent\n",
        "\n",
        "\n",
        "def compute_flops_params(model, input_shape, device):\n",
        "    if not THOP_AVAILABLE:\n",
        "        return 0.0, 0.0\n",
        "\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "    macs, params = profile(model, inputs=(dummy_input,), verbose=False)\n",
        "    flops_m = macs * 2 / 1e6\n",
        "    params_m = params / 1e6\n",
        "    return flops_m, params_m\n",
        "\n",
        "\n",
        "def measure_inference_time(model, input_shape, device, n_runs=100, warmup=10):\n",
        "    model.eval()\n",
        "    dummy_input = torch.randn(1, *input_shape).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(warmup):\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    start = time.time()\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_runs):\n",
        "            _ = model(dummy_input)\n",
        "\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.synchronize()\n",
        "\n",
        "    end = time.time()\n",
        "    return (end - start) / n_runs * 1000\n",
        "\n",
        "\n",
        "def compute_numerical_derivatives(signal, dt=1.0):\n",
        "    velocity = torch.zeros_like(signal)\n",
        "    velocity[:, :, 1:-1] = (signal[:, :, 2:] - signal[:, :, :-2]) / (2 * dt)\n",
        "    velocity[:, :, 0] = (signal[:, :, 1] - signal[:, :, 0]) / dt\n",
        "    velocity[:, :, -1] = (signal[:, :, -1] - signal[:, :, -2]) / dt\n",
        "    return velocity\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, dataset_name):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - {dataset_name}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'confusion_matrix_{dataset_name}.png', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_tsne(latents, labels, class_names, dataset_name):\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
        "    latents_2d = tsne.fit_transform(latents)\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        mask = labels == i\n",
        "        plt.scatter(latents_2d[mask, 0], latents_2d[mask, 1],\n",
        "                   label=class_name, alpha=0.6, s=20)\n",
        "    plt.legend()\n",
        "    plt.title(f't-SNE Visualization - {dataset_name}')\n",
        "    plt.xlabel('t-SNE 1')\n",
        "    plt.ylabel('t-SNE 2')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'tsne_{dataset_name}.png', dpi=150)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, scaler, epoch, seq_length):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_ce = 0\n",
        "    total_recon = 0\n",
        "    total_vel = 0\n",
        "    total_smooth = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data = data.to(device, non_blocking=True)\n",
        "        target = target.to(device, non_blocking=True)\n",
        "\n",
        "        batch_size = data.shape[0]\n",
        "\n",
        "        with autocast('cuda', enabled=USE_AMP):\n",
        "            if RANDOM_SAMPLING and epoch > 5:\n",
        "                num_observed = int(seq_length * SAMPLING_RATIO)\n",
        "                observed_indices = torch.randperm(seq_length)[:num_observed]\n",
        "                observed_indices, _ = torch.sort(observed_indices)\n",
        "\n",
        "                observed_times = observed_indices.float() / (seq_length - 1)\n",
        "                observed_times = observed_times.unsqueeze(0).unsqueeze(-1).expand(batch_size, -1, -1).to(device)\n",
        "                observed_data = data[:, :, observed_indices]\n",
        "\n",
        "                latent = model.encoder(data)\n",
        "                motion_observed = model.motion_field(latent, observed_times)\n",
        "                motion_observed = motion_observed.permute(0, 2, 1)\n",
        "\n",
        "                full_times = torch.linspace(0, 1, seq_length, device=device)\n",
        "                full_times = full_times.unsqueeze(0).unsqueeze(-1).expand(batch_size, -1, -1)\n",
        "                motion_full = model.motion_field(latent, full_times)\n",
        "                motion_full = motion_full.permute(0, 2, 1)\n",
        "\n",
        "                motion_stats = model.stat_extractor(motion_full)\n",
        "                combined_features = torch.cat([latent, motion_stats], dim=1)\n",
        "                logits = model.classifier(combined_features)\n",
        "\n",
        "                recon_loss = nn.functional.mse_loss(motion_observed, observed_data)\n",
        "            else:\n",
        "                logits, motion_full, latent = model(data)\n",
        "                recon_loss = nn.functional.mse_loss(motion_full, data)\n",
        "\n",
        "            ce_loss = nn.functional.cross_entropy(logits, target)\n",
        "\n",
        "            if DERIVATIVE_SUPERVISION:\n",
        "                num_deriv_points = 64\n",
        "                deriv_times = torch.linspace(0, 1, num_deriv_points, device=device)\n",
        "                deriv_times = deriv_times.unsqueeze(0).unsqueeze(-1).expand(batch_size, -1, -1)\n",
        "\n",
        "                with autocast('cuda', enabled=False):\n",
        "                    deriv_times_grad = deriv_times.clone().requires_grad_(True)\n",
        "                    motion_at_times = model.motion_field(latent.float(), deriv_times_grad)\n",
        "\n",
        "                    velocity_implicit = []\n",
        "                    for i in range(motion_at_times.shape[2]):\n",
        "                        grad_outputs = torch.ones_like(motion_at_times[:, :, i])\n",
        "                        grad = torch.autograd.grad(\n",
        "                            outputs=motion_at_times[:, :, i],\n",
        "                            inputs=deriv_times_grad,\n",
        "                            grad_outputs=grad_outputs,\n",
        "                            create_graph=True,\n",
        "                            retain_graph=True\n",
        "                        )[0]\n",
        "                        velocity_implicit.append(grad.squeeze(-1))\n",
        "\n",
        "                    velocity_implicit = torch.stack(velocity_implicit, dim=2)\n",
        "\n",
        "                    dt_full = 1.0 / (seq_length - 1)\n",
        "                    velocity_gt_full = compute_numerical_derivatives(data.float(), dt=dt_full)\n",
        "\n",
        "                    deriv_indices_full = (deriv_times.squeeze(-1) * (seq_length - 1)).clamp(0, seq_length - 1).long()\n",
        "                    velocity_numerical_list = []\n",
        "                    for i in range(batch_size):\n",
        "                        velocity_numerical_list.append(velocity_gt_full[i, :, deriv_indices_full[i]])\n",
        "\n",
        "                    velocity_numerical = torch.stack(velocity_numerical_list, dim=0)\n",
        "                    velocity_numerical = velocity_numerical.permute(0, 2, 1)\n",
        "\n",
        "                    velocity_loss = nn.functional.l1_loss(velocity_implicit, velocity_numerical)\n",
        "            else:\n",
        "                velocity_loss = torch.tensor(0.0, device=device)\n",
        "\n",
        "            random_times = torch.rand(batch_size, 50, 1, device=device)\n",
        "            dt_smoothness = 0.01\n",
        "            t1 = torch.clamp(random_times, 0, 1 - dt_smoothness)\n",
        "            t2 = t1 + dt_smoothness\n",
        "            m1 = model.motion_field(latent, t1)\n",
        "            m2 = model.motion_field(latent, t2)\n",
        "            temporal_derivative = (m2 - m1) / dt_smoothness\n",
        "            smoothness_loss = torch.mean(temporal_derivative ** 2)\n",
        "\n",
        "            loss = ce_loss + 0.5 * recon_loss + 0.1 * velocity_loss + 0.01 * smoothness_loss\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (batch_idx + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        total_loss += loss.item() * GRADIENT_ACCUMULATION_STEPS\n",
        "        total_ce += ce_loss.item()\n",
        "        total_recon += recon_loss.item()\n",
        "        total_vel += velocity_loss.item()\n",
        "        total_smooth += smoothness_loss.item()\n",
        "\n",
        "        pred = logits.argmax(dim=1)\n",
        "        correct += pred.eq(target).sum().item()\n",
        "        total += target.size(0)\n",
        "\n",
        "    return {\n",
        "        'loss': total_loss / len(train_loader),\n",
        "        'ce': total_ce / len(train_loader),\n",
        "        'recon': total_recon / len(train_loader),\n",
        "        'vel': total_vel / len(train_loader),\n",
        "        'smooth': total_smooth / len(train_loader),\n",
        "        'acc': 100. * correct / total\n",
        "    }\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, return_latents=False):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    all_latents = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data = data.to(device, non_blocking=True)\n",
        "            target = target.to(device, non_blocking=True)\n",
        "\n",
        "            with autocast('cuda', enabled=USE_AMP):\n",
        "                logits, motion_recon, latent = model(data, return_latent=True)\n",
        "\n",
        "                ce_loss = nn.functional.cross_entropy(logits, target)\n",
        "                recon_loss = nn.functional.mse_loss(motion_recon, data)\n",
        "                loss = ce_loss + 0.5 * recon_loss\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            pred = logits.argmax(dim=1)\n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "\n",
        "            if return_latents:\n",
        "                all_latents.append(latent.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    accuracy = accuracy_score(all_targets, all_preds) * 100\n",
        "    f1 = f1_score(all_targets, all_preds, average='weighted') * 100\n",
        "    precision = precision_score(all_targets, all_preds, average='weighted', zero_division=0) * 100\n",
        "    recall = recall_score(all_targets, all_preds, average='weighted', zero_division=0) * 100\n",
        "\n",
        "    if return_latents:\n",
        "        all_latents = np.vstack(all_latents)\n",
        "        return avg_loss, accuracy, f1, precision, recall, all_preds, all_targets, all_latents\n",
        "\n",
        "    return avg_loss, accuracy, f1, precision, recall, all_preds, all_targets\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"LOADING DATASETS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    datasets = {}\n",
        "\n",
        "    try:\n",
        "        X_train, y_train, X_test, y_test, activities = load_uci_har()\n",
        "        datasets['UCI-HAR'] = {\n",
        "            'X_train': X_train, 'y_train': y_train,\n",
        "            'X_test': X_test, 'y_test': y_test,\n",
        "            'activities': activities,\n",
        "            'input_channels': X_train.shape[1],\n",
        "            'seq_length': X_train.shape[2],\n",
        "            'num_classes': len(np.unique(y_train))\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"UCI-HAR failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        result = load_wisdm_data()\n",
        "        if result[0] is not None:\n",
        "            X_train, y_train, X_test, y_test, activities = result\n",
        "            datasets['WISDM'] = {\n",
        "                'X_train': X_train, 'y_train': y_train,\n",
        "                'X_test': X_test, 'y_test': y_test,\n",
        "                'activities': activities,\n",
        "                'input_channels': X_train.shape[1],\n",
        "                'seq_length': X_train.shape[2],\n",
        "                'num_classes': len(np.unique(y_train))\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"WISDM failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        result = load_pamap2_data()\n",
        "        if result[0] is not None:\n",
        "            X_train, y_train, X_test, y_test, activities = result\n",
        "            datasets['PAMAP2'] = {\n",
        "                'X_train': X_train, 'y_train': y_train,\n",
        "                'X_test': X_test, 'y_test': y_test,\n",
        "                'activities': activities,\n",
        "                'input_channels': X_train.shape[1],\n",
        "                'seq_length': X_train.shape[2],\n",
        "                'num_classes': len(np.unique(y_train))\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"PAMAP2 failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        result = load_mhealth_data()\n",
        "        if result[0] is not None:\n",
        "            X_train, y_train, X_test, y_test, activities = result\n",
        "            datasets['MHEALTH'] = {\n",
        "                'X_train': X_train, 'y_train': y_train,\n",
        "                'X_test': X_test, 'y_test': y_test,\n",
        "                'activities': activities,\n",
        "                'input_channels': X_train.shape[1],\n",
        "                'seq_length': X_train.shape[2],\n",
        "                'num_classes': len(np.unique(y_train))\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"MHEALTH failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        result = load_mobiact_data(\"/content/drive/MyDrive/HAR_Dataset/MOBIACT\")\n",
        "        if result[0] is not None:\n",
        "            X_train, y_train, X_test, y_test, activities = result\n",
        "            datasets['MobiAct'] = {\n",
        "                'X_train': X_train, 'y_train': y_train,\n",
        "                'X_test': X_test, 'y_test': y_test,\n",
        "                'activities': activities,\n",
        "                'input_channels': X_train.shape[1],\n",
        "                'seq_length': X_train.shape[2],\n",
        "                'num_classes': len(np.unique(y_train))\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"MobiAct failed: {e}\")\n",
        "\n",
        "    try:\n",
        "        result = load_motionsense_data()\n",
        "        if result[0] is not None:\n",
        "            X_train, y_train, X_test, y_test, activities = result\n",
        "            datasets['MotionSense'] = {\n",
        "                'X_train': X_train, 'y_train': y_train,\n",
        "                'X_test': X_test, 'y_test': y_test,\n",
        "                'activities': activities,\n",
        "                'input_channels': X_train.shape[1],\n",
        "                'seq_length': X_train.shape[2],\n",
        "                'num_classes': len(np.unique(y_train))\n",
        "            }\n",
        "    except Exception as e:\n",
        "        print(f\"MotionSense failed: {e}\")\n",
        "\n",
        "    if not datasets:\n",
        "        print(\"No datasets loaded! Exiting...\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nLoaded {len(datasets)} datasets: {list(datasets.keys())}\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset_name, data_info in datasets.items():\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"TRAINING ON: {dataset_name}\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Train samples: {data_info['X_train'].shape[0]}\")\n",
        "        print(f\"Test samples: {data_info['X_test'].shape[0]}\")\n",
        "        print(f\"Input shape: ({data_info['input_channels']}, {data_info['seq_length']})\")\n",
        "        print(f\"Classes: {data_info['num_classes']}\")\n",
        "\n",
        "        train_dataset = UCIHARDataset(data_info['X_train'], data_info['y_train'])\n",
        "        test_dataset = UCIHARDataset(data_info['X_test'], data_info['y_test'])\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=NUM_WORKERS,\n",
        "            pin_memory=True,\n",
        "            prefetch_factor=2\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=False,\n",
        "            num_workers=NUM_WORKERS,\n",
        "            pin_memory=True,\n",
        "            prefetch_factor=2\n",
        "        )\n",
        "\n",
        "        model = LightweightIMF(\n",
        "            input_channels=data_info['input_channels'],\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            latent_dim=LATENT_DIM,\n",
        "            num_classes=data_info['num_classes'],\n",
        "            seq_length=data_info['seq_length']\n",
        "        ).to(device)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"MODEL ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"Total Parameters: {total_params:,} ({total_params/1e6:.2f}M)\")\n",
        "        print(f\"Trainable Parameters: {trainable_params:,} ({trainable_params/1e6:.2f}M)\")\n",
        "\n",
        "        flops_value = 0.0\n",
        "        params_value = 0.0\n",
        "        inf_time = 0.0\n",
        "\n",
        "        if THOP_AVAILABLE:\n",
        "            input_shape = (data_info['input_channels'], data_info['seq_length'])\n",
        "            flops_value, params_value = compute_flops_params(model, input_shape, device)\n",
        "            print(f\"FLOPs: {flops_value:.2f}M\")\n",
        "            print(f\"Params (thop): {params_value:.2f}M\")\n",
        "\n",
        "            inf_time = measure_inference_time(model, input_shape, device)\n",
        "            print(f\"Inference Time: {inf_time:.2f}ms\")\n",
        "\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
        "        scaler = GradScaler('cuda', enabled=USE_AMP)\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"TRAINING STARTS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        best_acc = 0\n",
        "        best_f1 = 0\n",
        "\n",
        "        for epoch in range(1, EPOCHS + 1):\n",
        "            train_metrics = train_epoch(model, train_loader, optimizer, scaler, epoch, data_info['seq_length'])\n",
        "            test_loss, test_acc, test_f1, test_prec, test_rec, _, _ = evaluate(model, test_loader)\n",
        "            scheduler.step()\n",
        "\n",
        "            if epoch % 20 == 0 or epoch == 1:\n",
        "                print(f\"\\n{'='*70}\")\n",
        "                print(f\"EPOCH {epoch}/{EPOCHS} | Dataset: {dataset_name}\")\n",
        "                print(f\"{'='*70}\")\n",
        "                print(f\"TRAIN - Loss: {train_metrics['loss']:.4f} | Acc: {train_metrics['acc']:.2f}%\")\n",
        "                print(f\"   CE: {train_metrics['ce']:.4f} | Recon: {train_metrics['recon']:.4f} | Vel: {train_metrics['vel']:.4f} | Smooth: {train_metrics['smooth']:.4f}\")\n",
        "                print(f\"TEST  - Loss: {test_loss:.4f} | Acc: {test_acc:.2f}% | F1: {test_f1:.2f}% | Prec: {test_prec:.2f}% | Rec: {test_rec:.2f}%\")\n",
        "                print(f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "                if torch.cuda.is_available():\n",
        "                    print(f\"GPU Memory: {torch.cuda.max_memory_allocated()/1024**3:.2f} GB\")\n",
        "\n",
        "            if test_acc > best_acc:\n",
        "                best_acc = test_acc\n",
        "                best_f1 = test_f1\n",
        "                torch.save(model.state_dict(), f'imf_lightweight_{dataset_name}.pth')\n",
        "                if epoch % 20 == 0 or epoch == 1:\n",
        "                    print(f\"New best model saved! Acc: {best_acc:.2f}% | F1: {best_f1:.2f}%\")\n",
        "\n",
        "            if epoch % 50 == 0:\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"FINAL RESULTS - {dataset_name}\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        model.load_state_dict(torch.load(f'imf_lightweight_{dataset_name}.pth'))\n",
        "        _, final_acc, final_f1, final_prec, final_rec, preds, targets, latents = evaluate(model, test_loader, return_latents=True)\n",
        "\n",
        "        cm = confusion_matrix(targets, preds)\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        plot_confusion_matrix(cm, data_info['activities'], dataset_name)\n",
        "        print(f\"Confusion matrix saved: confusion_matrix_{dataset_name}.png\")\n",
        "\n",
        "        plot_tsne(latents, np.array(targets), data_info['activities'], dataset_name)\n",
        "        print(f\"t-SNE plot saved: tsne_{dataset_name}.png\")\n",
        "\n",
        "        print(\"\\nPer-class Accuracy:\")\n",
        "        for i, activity in enumerate(data_info['activities']):\n",
        "            if i < len(cm):\n",
        "                class_acc = cm[i, i] / cm[i].sum() * 100 if cm[i].sum() > 0 else 0\n",
        "                print(f\"  {activity}: {class_acc:.2f}%\")\n",
        "\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(f\"SUMMARY - {dataset_name}\")\n",
        "        print(\"=\"*70)\n",
        "        print(f\"Accuracy:  {final_acc:.2f}%\")\n",
        "        print(f\"F1 Score:  {final_f1:.2f}%\")\n",
        "        print(f\"Precision: {final_prec:.2f}%\")\n",
        "        print(f\"Recall:    {final_rec:.2f}%\")\n",
        "        print(f\"Params:    {total_params/1e6:.2f}M\")\n",
        "        print(f\"FLOPs:     {flops_value:.2f}M\")\n",
        "        print(f\"Inference: {inf_time:.2f}ms\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        all_results.append({\n",
        "            'Dataset': dataset_name,\n",
        "            'Accuracy': final_acc,\n",
        "            'F1': final_f1,\n",
        "            'Precision': final_prec,\n",
        "            'Recall': final_rec,\n",
        "            'Params (M)': total_params/1e6,\n",
        "            'FLOPs (M)': flops_value,\n",
        "            'Inference (ms)': inf_time\n",
        "        })\n",
        "\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"OVERALL RESULTS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    results_df = pd.DataFrame(all_results)\n",
        "    print(\"\\n\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    try:\n",
        "        from IPython.display import display\n",
        "        display(results_df)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    results_df.to_csv('imf_results.csv', index=False)\n",
        "    print(\"\\nResults saved to: imf_results.csv\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RTlBlh4aWKLC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}